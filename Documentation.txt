# DOCUMENTATION DU PROJET MISFAT

## 1. INTRODUCTION ET OBJECTIFS

Le projet MISFAT est un système d'analyse et de prévision de données énergétiques. Il permet de traiter, visualiser et prédire la consommation d'énergie à partir de données historiques stockées dans un fichier CSV (MISFAT(3) (1).csv).

Objectifs principaux :
- Analyser les tendances de consommation énergétique
- Créer des modèles de prévision à différentes échelles temporelles (journalière, hebdomadaire, mensuelle)
- Identifier les anomalies dans les données de consommation
- Fournir des visualisations interactives pour comprendre les schémas de consommation

Ce document sert de guide technique et pratique pour comprendre, utiliser et potentiellement étendre le projet MISFAT. Il est destiné aux ingénieurs, data scientists et développeurs qui souhaitent utiliser ou adapter ce système pour l'analyse de données énergétiques.

## 2. STRUCTURE DES DONNÉES ET PRÉTRAITEMENT

Le projet utilise un fichier CSV contenant des données temporelles de consommation énergétique avec plusieurs colonnes représentant différentes métriques de consommation (KWh).

### 2.1 Prétraitement des données

Plusieurs étapes de prétraitement sont appliquées aux données brutes :

- Conversion des valeurs textuelles en format numérique
- Traitement des formats de date et d'heure
- Nettoyage des valeurs manquantes par interpolation
- Suppression des colonnes inutiles
- Détection et sélection automatique des colonnes contenant des données non-nulles

Le prétraitement inclut également :
- La normalisation des formats numériques (remplacement des virgules par des points)
- La suppression des suffixes "kWh"
- La conversion des chaînes de caractères en valeurs flottantes

## 3. MÉTHODOLOGIE DE PRÉVISION

Le projet utilise une approche en trois niveaux pour la prévision énergétique :

1. **Prévision journalière** : Permet de prédire la consommation pour les prochains jours
2. **Prévision hebdomadaire** : Agrège les données quotidiennes pour prévoir les tendances sur plusieurs semaines
3. **Prévision mensuelle** : Analyse les tendances à long terme pour des prévisions mensuelles

Chaque niveau utilise des modèles adaptés à l'échelle temporelle concernée et intègre un mécanisme de repli (fallback) en cas d'échec du modèle principal.

## 4. MODÈLES DE PRÉVISION IMPLÉMENTÉS

### 4.1 Prévision journalière

Modèles principaux implémentés :
- **Prophet** : Modèle de Facebook pour les séries temporelles avec saisonnalité multiple
- **ARIMA** : Auto-Regressive Integrated Moving Average
- **Prévision naïve** : Utilisation de la dernière valeur connue comme prédiction

### 4.2 Prévision hebdomadaire

Modèles principaux implémentés :
- **Prophet** : Adapté pour capturer les tendances hebdomadaires
- **ARIMA** : Configuré pour les données hebdomadaires
- **SES** (Simple Exponential Smoothing) : Utilisé comme modèle de secours

### 4.3 Prévision mensuelle

Modèles principaux implémentés :
- **Exponential Smoothing** : Avec composantes de tendance et de saisonnalité
- **Simple Exponential Smoothing** : Utilisé comme alternative si les données sont insuffisantes
- **Prévision naïve** : Dernier recours si les autres modèles échouent

## 5. FONCTIONNEMENT DES DIFFÉRENTS MODÈLES

### 5.1 Prophet

Prophet est un modèle développé par Facebook pour la prévision de séries temporelles qui décompose les données en trois composantes :
- Tendance (croissance ou décroissance à long terme)
- Saisonnalité (motifs hebdomadaires et annuels)
- Effets des jours fériés

Dans le projet MISFAT, Prophet est configuré avec les paramètres suivants :
- `yearly_seasonality=True` : Capture les motifs annuels
- `weekly_seasonality=True` : Capture les motifs hebdomadaires
- `daily_seasonality=False` : Ignore les motifs quotidiens (insuffisants pour les données)
- `seasonality_mode='multiplicative'` : Utilise un modèle multiplicatif pour la saisonnalité

Le modèle utilise un processus en quatre étapes :
1. Préparation des données dans le format requis par Prophet (colonnes 'ds' et 'y')
2. Entraînement du modèle sur les données historiques
3. Création d'un dataframe pour la période de prévision
4. Génération des prévisions et visualisation des résultats

### 5.2 ARIMA (Auto-Regressive Integrated Moving Average)

ARIMA est un modèle statistique classique pour les séries temporelles qui combine trois concepts :
- Auto-Régression (AR) : Utilise la dépendance entre une observation et un nombre spécifié d'observations décalées
- Différenciation (I) : Rend la série temporelle stationnaire en soustrayant les valeurs précédentes
- Moyenne Mobile (MA) : Modélise l'erreur comme une combinaison linéaire d'erreurs passées

Dans MISFAT, ARIMA est configuré avec les paramètres (5,1,0) :
- p=5 : Ordre d'auto-régression de 5
- d=1 : Différenciation d'ordre 1
- q=0 : Pas de composante de moyenne mobile

Le modèle est utilisé comme solution de secours lorsque Prophet échoue, notamment sur des séries temporelles avec peu de données ou des données irrégulières.

### 5.3 Simple Exponential Smoothing (SES)

Le lissage exponentiel simple est une technique qui accorde progressivement moins d'importance aux observations à mesure qu'elles vieillissent. Le modèle est particulièrement adapté aux séries sans tendance ni saisonnalité claire.

Dans MISFAT, SES est implémenté comme une seconde solution de secours lorsque Prophet et ARIMA échouent. Il est plus robuste aux données limitées ou bruitées.

### 5.4 Exponential Smoothing

Le lissage exponentiel (avec ses variantes) est utilisé principalement pour les prévisions mensuelles. Le modèle peut intégrer :
- Une composante de tendance (additive)
- Une composante saisonnière (additive ou multiplicative)

Pour les prévisions mensuelles, deux configurations sont possibles :

1. **Configuration avec saisonnalité** (lorsque suffisamment de données sont disponibles) :
   - `trend='add'` : Tendance additive
   - `seasonal='add'` : Saisonnalité additive
   - `seasonal_periods=12` : Cycle de 12 mois

2. **Configuration sans saisonnalité** (pour les données limitées) :
   - `trend='add'` : Tendance additive
   - `seasonal=None` : Pas de composante saisonnière

## 6. PROBLÈMES RENCONTRÉS ET SOLUTIONS APPORTÉES

### 6.1 Insuffisance de données pour les prévisions mensuelles

**Problème** : Le modèle Exponential Smoothing avec saisonnalité nécessite au moins deux cycles saisonniers complets (24 mois) pour estimer les composantes saisonnières initiales.

**Solution** : Une approche adaptative a été implémentée :
- Vérification de la quantité de données disponibles
- Si moins de 24 mois de données sont disponibles, utilisation d'un modèle sans composante saisonnière
- Si l'entraînement échoue encore, utilisation du Simple Exponential Smoothing
- En dernier recours, utilisation d'une prévision naïve basée sur la dernière valeur connue

### 6.2 Gestion des valeurs manquantes ou nulles

**Problème** : Les données contiennent de nombreuses valeurs nulles qui peuvent perturber les modèles de prévision.

**Solutions** :
- Interpolation linéaire pour combler les valeurs manquantes
- Détection automatique des colonnes contenant des données non-nulles
- Traitement spécifique des NaN dans les ensembles d'entraînement et de test
- Utilisation de masques pour ignorer les valeurs NaN lors de l'évaluation des modèles

### 6.3 Évaluation des modèles robuste

**Problème** : L'évaluation des modèles peut être biaisée par des valeurs extrêmes ou manquantes.

**Solutions** :
- Implémentation de plusieurs métriques d'évaluation (MAE, MSE, RMSE, MAPE)
- Création d'un mécanisme de masquage pour ignorer les valeurs NaN lors de l'évaluation
- Affichage d'avertissements clairs lorsque l'évaluation est limitée par la qualité des données

## 7. FONCTIONNEMENT DE LA PRÉVISION MENSUELLE

La fonction `monthly_forecast` améliorée fonctionne comme suit :

1. **Vérification des données disponibles** :
   - Vérifie s'il y a suffisamment de mois uniques (au moins 2)
   - Vérifie s'il y a au moins 3 mois de données pour une prévision fiable

2. **Préparation des données** :
   - Agrégation des données par mois (moyenne mensuelle)
   - Division en ensembles d'entraînement (80%) et de test (20%)

3. **Sélection du modèle approprié** :
   - Vérifie s'il y a au moins 24 mois de données (2 années complètes)
   - Si oui, utilise ExponentialSmoothing avec composante saisonnière
   - Sinon, utilise ExponentialSmoothing sans composante saisonnière

4. **Gestion des erreurs et solutions de secours** :
   - En cas d'échec du premier modèle, essaie Simple Exponential Smoothing
   - Si SES échoue également, utilise une prévision naïve (dernière valeur connue)

5. **Évaluation et visualisation** :
   - Évaluation du modèle sur les données de test si disponibles
   - Visualisation des données d'entraînement, de test et des prévisions
   - Affichage des métriques de performance (MAE, MSE, RMSE, MAPE)

Cette approche garantit que la prévision mensuelle fonctionne même avec des données limitées, en s'adaptant automatiquement à la quantité et à la qualité des données disponibles.

## 8. INTERPRÉTATION DES VISUALISATIONS DE DONNÉES

### 8.1 Séries temporelles brutes et agrégées

Les visualisations de séries temporelles dans le projet MISFAT suivent une structure cohérente :

- **Données brutes (ligne bleue)** : Représentent les valeurs historiques réelles enregistrées
- **Données de test (ligne rouge)** : Portion des données réservée pour évaluer la performance du modèle
- **Prévisions (ligne verte)** : Valeurs prédites par le modèle
- **Intervalle de confiance (zone ombrée)** : Marge d'erreur probable pour les prévisions

**Que rechercher dans ces graphiques :**

1. **Continuité entre données de test et prévisions** : Une bonne prévision devrait suivre naturellement les données de test sans sauts brusques ou discontinuités
   
2. **Capture des tendances saisonnières** : Vérifiez si les cycles observés dans les données historiques se retrouvent dans les prévisions
   
3. **Largeur des intervalles de confiance** : Des intervalles trop larges indiquent une grande incertitude, tandis que des intervalles trop étroits peuvent sous-estimer l'incertitude

### 8.2 Graphiques de décomposition

Les graphiques de décomposition (particulièrement visibles avec Prophet) divisent la série temporelle en composantes :

- **Tendance** : Évolution à long terme (croissance ou décroissance générale)
- **Saisonnalité hebdomadaire** : Motifs répétitifs sur une semaine
- **Saisonnalité annuelle** : Motifs liés aux saisons ou périodes de l'année
- **Résidus** : Variations non expliquées par les composantes ci-dessus

**Interprétation des composantes :**

1. **Tendance forte** : Indique un changement structurel dans la consommation énergétique
2. **Saisonnalité marquée** : Révèle des cycles d'utilisation réguliers (ex: consommation plus élevée en semaine que le weekend)
3. **Résidus importants** : Peuvent indiquer des événements spéciaux ou des anomalies non modélisées

### 8.3 Graphiques d'évaluation

Les graphiques de dispersion et d'erreur montrent la relation entre valeurs réelles et prédites :

- **Graphique de dispersion (scatter plot)** : Les points proches de la diagonale indiquent des prévisions précises
- **Distribution des erreurs** : Idéalement centrée sur zéro et suivant une distribution normale
- **Graphique d'erreur temporelle** : Montre si les erreurs sont uniformes dans le temps ou concentrées sur certaines périodes

**Points d'attention :**

1. **Valeurs aberrantes** : Points éloignés de la diagonale dans le graphique de dispersion
2. **Biais systématique** : Distribution des erreurs non centrée sur zéro
3. **Hétéroscédasticité** : Variance de l'erreur qui change selon l'amplitude des valeurs prédites

### 8.4 Visualisations des anomalies

Les graphiques d'anomalies sont représentés par :

- **Série temporelle avec points colorés** : Les points rouges indiquent les anomalies détectées
- **Score d'anomalie** : Graphique montrant le score d'anormalité de chaque point

**Comment interpréter :**

1. **Fréquence des anomalies** : Un grand nombre d'anomalies peut indiquer soit un problème réel, soit un seuil de détection trop sensible
2. **Régularité des anomalies** : Des anomalies regroupées peuvent indiquer un événement particulier (panne, maintenance)
3. **Amplitude des anomalies** : Distinguer entre anomalies mineures et majeures selon leur écart par rapport à la normale

## 9. EXPLICATION DES MÉTRIQUES D'ÉVALUATION DES MODÈLES

### 9.1 Métriques d'erreur principales

Le projet MISFAT utilise plusieurs métriques pour évaluer la qualité des prévisions :

#### MAE (Mean Absolute Error - Erreur Absolue Moyenne)
**Formule** : $MAE = \frac{1}{n}\sum_{i=1}^{n} |y_i - \hat{y}_i|$

**Interprétation** : Mesure l'erreur moyenne en valeur absolue, exprimée dans la même unité que les données (kWh).
**Avantages** : Facile à comprendre, non influencée par la direction de l'erreur.
**Seuil acceptable** : Dépend de l'amplitude des données, mais généralement < 5-10% de la valeur moyenne.

#### MSE (Mean Squared Error - Erreur Quadratique Moyenne)
**Formule** : $MSE = \frac{1}{n}\sum_{i=1}^{n} (y_i - \hat{y}_i)^2$

**Interprétation** : Mesure la moyenne des carrés des erreurs, pénalisant davantage les grandes erreurs.
**Avantages** : Utile pour pénaliser les grandes erreurs, mathématiquement pratique pour l'optimisation.
**Inconvénients** : Exprimée dans le carré de l'unité des données (kWh²), difficile à interpréter directement.

#### RMSE (Root Mean Squared Error - Racine Carrée de l'Erreur Quadratique Moyenne)
**Formule** : $RMSE = \sqrt{MSE} = \sqrt{\frac{1}{n}\sum_{i=1}^{n} (y_i - \hat{y}_i)^2}$

**Interprétation** : Racine carrée du MSE, exprimée dans la même unité que les données (kWh).
**Avantages** : Comparable à l'échelle des données, pénalise les grandes erreurs.
**Seuil acceptable** : Généralement < 10-15% de la valeur moyenne.

#### MAPE (Mean Absolute Percentage Error - Erreur Absolue Moyenne en Pourcentage)
**Formule** : $MAPE = \frac{100\%}{n}\sum_{i=1}^{n} |\frac{y_i - \hat{y}_i}{y_i}|$

**Interprétation** : Erreur moyenne en pourcentage, indépendante de l'échelle des données.
**Avantages** : Facile à interpréter, permet de comparer des séries de différentes amplitudes.
**Inconvénients** : Indéfinie ou instable quand les valeurs réelles sont proches de zéro, ce qui est fréquent dans les données MISFAT.
**Seuil acceptable** : < 10% est excellent, < 20% est bon, > 50% indique un modèle problématique.

### 9.2 Choix de la métrique selon le contexte

**Pour la production** : Le choix de la métrique dépend des conséquences des erreurs de prévision :

- **MAE** : Préférable quand l'impact des erreurs est proportionnel à leur taille.
- **RMSE** : Meilleure quand les grandes erreurs sont particulièrement problématiques (ex: dimensionnement d'installations).
- **MAPE** : Utile pour communiquer avec les non-spécialistes, car exprimée en pourcentage.

**Remarque importante pour MISFAT** : Étant donné que les données contiennent beaucoup de valeurs nulles ou très faibles, le MAPE peut donner des résultats trompeurs. Dans ce cas, privilégier le MAE ou le RMSE.

### 9.3 Évaluation comparative des modèles

**Benchmark simple** : La prévision naïve (utilisant la dernière valeur connue) sert de référence.

**Interprétation des améliorations** :
- **Amélioration < 5%** : Marginale, probablement pas significative
- **Amélioration 5-20%** : Notable, justifie l'utilisation du modèle plus complexe
- **Amélioration > 20%** : Substantielle, indique un modèle nettement meilleur

**Validation croisée** : Pour des évaluations plus robustes, le projet pourrait bénéficier d'une validation croisée temporelle, où plusieurs périodes de test sont utilisées pour évaluer la stabilité du modèle.

## 10. DÉTAILS TECHNIQUES D'IMPLÉMENTATION DES MODÈLES

### 10.1 Structure du code et organisation

Le projet MISFAT est structuré sous forme de notebook Jupyter avec des fonctions modulaires pour chaque étape du processus :

```
- Chargement et nettoyage des données
- Fonctions d'agrégation temporelle (journalière, hebdomadaire, mensuelle)
- Modèles de prévision pour chaque échelle temporelle
- Fonctions d'évaluation et de visualisation
- Détection d'anomalies
```

Cette modularité permet d'adapter facilement le code pour différents jeux de données ou contextes.

### 10.2 Implémentation technique de Prophet

**Dépendances requises** :
- `prophet` (dépendance principale)
- `pandas` (préparation des données)
- `matplotlib` (visualisation)

**Structure des données** :
Prophet exige un format spécifique avec deux colonnes obligatoires :
- `ds` : dates/timestamps (format datetime)
- `y` : valeurs cibles (format numérique)

**Exemple de code d'implémentation** :
```python
from prophet import Prophet

# Préparation des données
train_df = pd.DataFrame({
    'ds': df.index[:-forecast_periods],
    'y': df[column][:-forecast_periods]
})

# Configuration et entraînement du modèle
model = Prophet(
    yearly_seasonality=True,
    weekly_seasonality=True,
    daily_seasonality=False,
    seasonality_mode='multiplicative'
)
model.fit(train_df)

# Création d'un dataframe pour la période de prévision
future = model.make_future_dataframe(periods=forecast_periods, freq='D')

# Génération des prévisions
forecast = model.predict(future)
```

**Optimisation des hyperparamètres** :
Les hyperparamètres de Prophet peuvent être ajustés pour améliorer la qualité des prévisions :
- `changepoint_prior_scale` : contrôle la flexibilité de la tendance (défaut : 0.05)
- `seasonality_prior_scale` : contrôle la force de la saisonnalité (défaut : 10)
- `holidays_prior_scale` : impact des jours fériés (défaut : 10)

### 10.3 Implémentation technique d'ARIMA

**Dépendances requises** :
- `statsmodels` (contient l'implémentation d'ARIMA)
- `pandas` et `numpy` (manipulation des données)

**Structure des données** :
ARIMA utilise une série temporelle unidimensionnelle comme entrée.

**Exemple de code d'implémentation** :
```python
from statsmodels.tsa.arima.model import ARIMA

# Préparation des données (suppression des NaN)
clean_train = train.dropna()

# Configuration et entraînement du modèle
model = ARIMA(clean_train, order=(5, 1, 0))
model_fit = model.fit()

# Génération des prévisions
forecast = model_fit.forecast(steps=forecast_periods)
```

**Paramètres ARIMA** :
Les paramètres (p,d,q) contrôlent le comportement du modèle :
- `p` : Ordre autorégressif (nombre de décalages)
- `d` : Degré de différenciation pour rendre la série stationnaire
- `q` : Ordre de moyenne mobile (taille de la fenêtre d'erreur)

### 10.4 Implémentation technique du lissage exponentiel

**Dépendances requises** :
- `statsmodels` (contient les implémentations de lissage exponentiel)

**Structure des données** :
Série temporelle unidimensionnelle, idéalement sans valeurs manquantes.

**Exemples de code d'implémentation** :

**Lissage exponentiel simple (SES)** :
```python
from statsmodels.tsa.holtwinters import SimpleExpSmoothing

model = SimpleExpSmoothing(train)
model_fit = model.fit()
forecast = model_fit.forecast(steps=forecast_periods)
```

**Lissage exponentiel avec tendance et saisonnalité** :
```python
from statsmodels.tsa.holtwinters import ExponentialSmoothing

# Configuration avec saisonnalité
model = ExponentialSmoothing(
    train,
    trend='add',
    seasonal='add',
    seasonal_periods=12  # Cycle mensuel
)
model_fit = model.fit()
forecast = model_fit.forecast(steps=forecast_periods)
```

**Adaptation aux données limitées** :
```python
# Sans saisonnalité pour les séries courtes
model = ExponentialSmoothing(
    train,
    trend='add',
    seasonal=None
)
```

### 10.5 Traitement des erreurs et mécanismes de repli

Le projet utilise un système de gestion des erreurs à plusieurs niveaux :

1. **Détection précoce de problèmes** :
   ```python
   if len(df.index.month.unique()) <= 1:
       print("Pas assez de données pour une prévision mensuelle")
       return None, None
   ```

2. **Structure try/except avec modèles alternatifs** :
   ```python
   try:
       # Tentative avec le modèle principal
   except Exception as e:
       print(f"Erreur avec le modèle principal: {e}")
       try:
           # Tentative avec modèle de secours
       except Exception as e2:
           print(f"Erreur avec le modèle de secours: {e2}")
           # Utilisation de la méthode naïve
   ```

3. **Méthode naïve comme dernier recours** :
   ```python
   # Prévision naïve - utilise la dernière valeur connue
   forecast = pd.Series(
       [train.iloc[-1]] * len(forecast_index),
       index=forecast_index
   )
   ```

## 11. CONSEILS D'UTILISATION PRATIQUE DU NOTEBOOK

### 11.1 Configuration de l'environnement

**Prérequis** :
- Python 3.7 ou supérieur
- Jupyter Notebook ou JupyterLab

**Bibliothèques requises** :
```
pandas
numpy
matplotlib
statsmodels
prophet
scikit-learn
```

**Installation** :
```bash
pip install pandas numpy matplotlib statsmodels prophet scikit-learn jupyter
```

### 11.2 Chargement des données

**Format des données source** :
- Le fichier CSV doit contenir une colonne de date/heure
- Les valeurs de consommation doivent être numériques ou convertibles en nombres

**Adaptation à d'autres sources de données** :
1. Modifier la section de chargement des données pour s'adapter au format source
2. Adapter les étapes de nettoyage selon les particularités des données
3. Vérifier la fréquence temporelle des données et ajuster les paramètres d'agrégation

### 11.3 Personnalisation des modèles

**Ajustement des périodes de prévision** :
- Modifier les variables `forecast_days`, `forecast_weeks` ou `forecast_months` selon les besoins

**Optimisation des modèles** :
- Prophet : ajuster les paramètres `changepoint_prior_scale`, `seasonality_prior_scale`
- ARIMA : modifier l'ordre (p,d,q) selon les caractéristiques des données
- Lissage exponentiel : ajuster les paramètres alpha, beta, gamma selon la dynamique des données

### 11.4 Interprétation des résultats

**Analyse des prévisions** :
1. Examiner les graphiques pour identifier les tendances et comportements saisonniers
2. Comparer les métriques d'erreur entre les différents modèles
3. Vérifier si les intervalles de confiance sont raisonnables

**Diagnostic des problèmes** :
- Prévisions trop lisses : le modèle ne capture pas la variabilité des données
- Prévisions trop bruitées : le modèle est trop sensible aux fluctuations aléatoires
- Écart systématique : biais dans les prévisions, nécessite une réévaluation du modèle

### 11.5 Extension et personnalisation

**Ajout de nouvelles fonctionnalités** :
- Intégration d'autres modèles de prévision (ex: LSTM, Réseaux de neurones)
- Ajout de variables exogènes (température, jour férié, etc.)
- Amélioration des visualisations (graphiques interactifs avec Plotly)

**Automatisation** :
- Conversion du notebook en scripts Python pour l'exécution automatisée
- Création d'un pipeline ETL pour le traitement régulier de nouvelles données
- Mise en place d'alertes basées sur les anomalies détectées

## 12. CRÉATION D'UNE INTERFACE GRAPHIQUE

### 12.1 Options technologiques pour l'interface

Plusieurs technologies peuvent être utilisées pour créer une interface graphique à partir du projet MISFAT :

#### 1. Application Web

**Technologies recommandées** :
- **Backend** : Flask ou FastAPI (Python)
- **Frontend** : React, Vue.js ou simple HTML/CSS/JavaScript
- **Visualisations** : Plotly, D3.js ou Chart.js

**Avantages** :
- Accessible via navigateur sans installation
- Facilement déployable sur un serveur
- Interface responsive pour différents appareils

#### 2. Application de bureau

**Technologies recommandées** :
- PyQt ou PySide (interfaces Qt en Python)
- Tkinter (plus simple mais moins moderne)
- Electron (pour une application hybride web/desktop)

**Avantages** :
- Performance optimale pour l'analyse locale
- Fonctionnement hors ligne
- Intégration plus profonde avec le système d'exploitation

#### 3. Dashboard interactif

**Technologies recommandées** :
- Streamlit (solution la plus simple)
- Dash by Plotly
- Panel ou Voilà (basés sur Jupyter)

**Avantages** :
- Développement très rapide
- Excellentes capacités de visualisation
- Transformation facile du notebook existant

### 12.2 Architecture recommandée

Une architecture en trois couches est recommandée :

1. **Couche de données** :
   - Gestion de la lecture/écriture des fichiers CSV
   - Prétraitement et nettoyage des données
   - Stockage des résultats (fichiers ou base de données)

2. **Couche métier** :
   - Implémentation des modèles de prévision
   - Logique d'évaluation et de comparaison
   - Détection d'anomalies

3. **Couche présentation** :
   - Interface utilisateur
   - Visualisations interactives
   - Contrôles pour paramétrer les modèles

### 12.3 Guide de mise en œuvre avec Streamlit

Streamlit est recommandé pour une première implémentation rapide de l'interface graphique :

**Étape 1 : Installation** :
```bash
pip install streamlit pandas numpy matplotlib statsmodels prophet scikit-learn plotly
```

**Étape 2 : Structure du projet** :
```
misfat_app/
├── app.py            # Point d'entrée de l'application Streamlit
├── data_loader.py    # Fonctions de chargement et prétraitement
├── models.py         # Implémentation des modèles de prévision
├── visualization.py  # Fonctions de visualisation
└── data/             # Dossier pour les données
    └── MISFAT(3) (1).csv
```

**Étape 3 : Exemple de code app.py** :
```python
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import plotly.express as px
from data_loader import load_data, preprocess_data
from models import daily_forecast, weekly_forecast, monthly_forecast
from visualization import plot_forecast_results

# Configuration de la page
st.set_page_config(page_title="MISFAT Dashboard", layout="wide")

# Titre
st.title("MISFAT - Analyse et Prévision de Consommation Énergétique")

# Chargement des données
data_file = st.sidebar.file_uploader("Charger un fichier CSV", type=["csv"])

if data_file is not None:
    # Chargement et prétraitement
    df = load_data(data_file)
    df = preprocess_data(df)
    
    # Affichage des données brutes
    st.subheader("Aperçu des données")
    st.dataframe(df.head())
    
    # Sélection de la colonne à analyser
    columns = [col for col in df.columns if col != 'Date']
    selected_column = st.sidebar.selectbox("Sélectionner une métrique", columns)
    
    # Visualisation des données historiques
    st.subheader(f"Données historiques - {selected_column}")
    fig = px.line(df, x=df.index, y=selected_column)
    st.plotly_chart(fig, use_container_width=True)
    
    # Paramètres de prévision
    forecast_type = st.sidebar.radio(
        "Type de prévision",
        ["Journalière", "Hebdomadaire", "Mensuelle"]
    )
    
    if forecast_type == "Journalière":
        forecast_periods = st.sidebar.slider("Nombre de jours à prévoir", 1, 90, 30)
        forecast, metrics = daily_forecast(df, selected_column, forecast_periods)
    elif forecast_type == "Hebdomadaire":
        forecast_periods = st.sidebar.slider("Nombre de semaines à prévoir", 1, 26, 4)
        forecast, metrics = weekly_forecast(df, selected_column, forecast_periods)
    else:  # Mensuelle
        forecast_periods = st.sidebar.slider("Nombre de mois à prévoir", 1, 12, 3)
        forecast, metrics = monthly_forecast(df, selected_column, forecast_periods)
    
    # Affichage des résultats de prévision
    if forecast is not None:
        st.subheader("Résultats de la prévision")
        forecast_fig = plot_forecast_results(df, selected_column, forecast)
        st.plotly_chart(forecast_fig, use_container_width=True)
        
        # Métriques d'évaluation
        if metrics is not None:
            st.subheader("Métriques d'évaluation")
            metrics_df = pd.DataFrame(metrics, index=[0])
            st.dataframe(metrics_df)
    else:
        st.error("Impossible de générer une prévision avec les données actuelles.")
else:
    st.info("Veuillez charger un fichier CSV pour commencer l'analyse.")
```

**Étape 4 : Exécution de l'application** :
```bash
streamlit run app.py
```

### 12.4 Extensions possibles

1. **Fonctionnalités supplémentaires** :
   - Téléchargement des résultats de prévision au format CSV
   - Comparaison côte à côte de différents modèles
   - Analyse détaillée des composantes de la série temporelle

2. **Améliorations de l'interface** :
   - Thème personnalisé aux couleurs de l'entreprise
   - Mode sombre/clair
   - Tableaux de bord spécifiques selon le rôle de l'utilisateur

3. **Déploiement** :
   - Conteneurisation avec Docker
   - Déploiement sur un serveur web ou cloud (Heroku, AWS, Azure)
   - Configuration d'une mise à jour automatique des données

## 13. CONCLUSION

Le projet MISFAT offre une solution complète pour l'analyse et la prévision de données de consommation énergétique. Sa force réside dans :

1. **L'adaptabilité** : Plusieurs modèles et mécanismes de repli pour s'adapter à différentes situations de données
2. **La robustesse** : Gestion élégante des erreurs et des cas limites
3. **La flexibilité** : Prévisions à différentes échelles temporelles (jour, semaine, mois)
4. **La visualisation** : Représentations graphiques claires des données et des prévisions

Les corrections apportées à la fonction de prévision mensuelle permettent désormais de gérer correctement les cas où les données historiques sont limitées, en adaptant le modèle utilisé à la quantité de données disponibles.

Avec les instructions détaillées pour la création d'une interface graphique, le projet peut maintenant évoluer vers une application complète et conviviale, permettant aux utilisateurs non techniques d'exploiter pleinement ses capacités d'analyse et de prévision.